{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "93ec15db",
   "metadata": {},
   "source": [
    "필요 라이브러리 설치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08b39572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: ipywidgets in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.0)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.51)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.13.2)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure_eval in /opt/anaconda3/envs/ai/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "usage: jupyter [-h] [--version] [--config-dir] [--data-dir] [--runtime-dir]\n",
      "               [--paths] [--json] [--debug]\n",
      "               [subcommand]\n",
      "\n",
      "Jupyter: Interactive Computing\n",
      "\n",
      "positional arguments:\n",
      "  subcommand     the subcommand to launch\n",
      "\n",
      "options:\n",
      "  -h, --help     show this help message and exit\n",
      "  --version      show the versions of core jupyter packages and exit\n",
      "  --config-dir   show Jupyter config dir\n",
      "  --data-dir     show Jupyter data dir\n",
      "  --runtime-dir  show Jupyter runtime dir\n",
      "  --paths        show all Jupyter paths. Add --json for machine-readable\n",
      "                 format.\n",
      "  --json         output paths as machine-readable json\n",
      "  --debug        output debug information about paths\n",
      "\n",
      "Available subcommands: dejavu events execute kernel kernelspec lab\n",
      "labextension labhub migrate nbconvert notebook run server troubleshoot trust\n",
      "\n",
      "Jupyter command `jupyter-nbextension` not found.\n"
     ]
    }
   ],
   "source": [
    "# (필요 시, colab/로컬 환경에서 먼저 설치)\n",
    "%pip install transformers torch tqdm --quiet\n",
    "%pip install ipywidgets --upgrade\n",
    "!jupyter nbextension enable --py widgetsnbextension\n",
    "\n",
    "import json\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import ElectraTokenizer, ElectraForSequenceClassification\n",
    "from torch.optim import AdamW\n",
    "from tqdm.notebook import tqdm\n",
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6a7bea",
   "metadata": {},
   "source": [
    "하이퍼파라미터 및 경로 세팅"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3912ab52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 경로 및 세팅\n",
    "MODEL_NAME = \"monologg/koelectra-base-v3-discriminator\"\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 4\n",
    "LR = 2e-5\n",
    "MAX_LEN = 64\n",
    "\n",
    "TRAIN_PATH = \"/mnt/data/train.json\"\n",
    "VALID_PATH = \"/mnt/data/valid.json\"\n",
    "TEST_PATH  = \"/mnt/data/test_cls.json\"\n",
    "OUTPUT_PATH = \"../outputs/cls_output.json\"\n",
    "MODEL_SAVE_PATH = \"./koelectra_cls.pt\"\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286979cc",
   "metadata": {},
   "source": [
    "데이터셋 클래스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18bcddfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QCDataset(Dataset):\n",
    "    def __init__(self, data, tokenizer, max_len, with_label=True):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "        self.with_label = with_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.data[idx]\n",
    "        encoded = self.tokenizer(\n",
    "            item['question'],\n",
    "            max_length=self.max_len,\n",
    "            truncation=True,\n",
    "            padding='max_length',\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        inputs = {k: v.squeeze() for k, v in encoded.items()}\n",
    "        if self.with_label and 'label' in item:\n",
    "            inputs['labels'] = torch.tensor(item['label'])\n",
    "        return inputs\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca5d0ee",
   "metadata": {},
   "source": [
    "데이터 로드/토크나이저 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb4bc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 로드\n",
    "def load_json(path):\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "train_data = load_json(\"../data/train.json\")\n",
    "valid_data = load_json(\"../data/valid.json\")\n",
    "test_data  = load_json(\"../data/test_cls.json\")\n",
    "\n",
    "tokenizer = ElectraTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "train_ds = QCDataset(train_data, tokenizer, MAX_LEN)\n",
    "valid_ds = QCDataset(valid_data, tokenizer, MAX_LEN)\n",
    "test_ds  = QCDataset(test_data, tokenizer, MAX_LEN, with_label=False)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "valid_loader = DataLoader(valid_ds, batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(test_ds, batch_size=BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e836fa",
   "metadata": {},
   "source": [
    "모델 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4078dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at monologg/koelectra-base-v3-discriminator and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=5)\n",
    "model = model.to(DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef880756",
   "metadata": {},
   "source": [
    "학습 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "baa83ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, optimizer):\n",
    "    model.train()\n",
    "    losses = []\n",
    "    for batch in tqdm(dataloader):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "        losses.append(loss.item())\n",
    "    return np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75a3cbbf",
   "metadata": {},
   "source": [
    "검증 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "07aef7ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model, dataloader):\n",
    "    model.eval()\n",
    "    preds, trues = [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            input_ids = batch['input_ids'].to(DEVICE)\n",
    "            attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "            labels = batch['labels'].to(DEVICE)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits.cpu().numpy()\n",
    "            batch_preds = np.argmax(logits, axis=1)\n",
    "            preds.extend(batch_preds)\n",
    "            trues.extend(labels.cpu().numpy())\n",
    "    acc = accuracy_score(trues, preds)\n",
    "    f1 = f1_score(trues, preds, average='macro')\n",
    "    return acc, f1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5f454a4",
   "metadata": {},
   "source": [
    "전체 학습 루프"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f11299e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff55b6bfb6134e759e13b3fc4e3e9bb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.1564 | Valid Acc: 0.9069 | Valid F1: 0.9015\n",
      "Best model saved!\n",
      "Epoch 2/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c51126e64389414caa1b9777a3ecd6fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0053 | Valid Acc: 0.8777 | Valid F1: 0.8743\n",
      "Epoch 3/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "613cb6efc7134fcdadde199d2d54b983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0012 | Valid Acc: 0.9307 | Valid F1: 0.9293\n",
      "Best model saved!\n",
      "Epoch 4/4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f21eca5971524e468db28a53237c4c4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/719 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss: 0.0003 | Valid Acc: 0.9375 | Valid F1: 0.9359\n",
      "Best model saved!\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=LR)\n",
    "\n",
    "best_f1 = 0\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}\")\n",
    "    train_loss = train_one_epoch(model, train_loader, optimizer)\n",
    "    acc, f1 = eval_model(model, valid_loader)\n",
    "    print(f\"Train loss: {train_loss:.4f} | Valid Acc: {acc:.4f} | Valid F1: {f1:.4f}\")\n",
    "    if f1 > best_f1:\n",
    "        torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "        best_f1 = f1\n",
    "        print(\"Best model saved!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d0cb44",
   "metadata": {},
   "source": [
    "추론 및 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f72708f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def refine_label(question, predicted_label):\n",
    "    q = question.lower()\n",
    "\n",
    "    # 1. 장학금 복합 케이스\n",
    "    if '장학' in q:\n",
    "        if any(k in q for k in ['발표', '결과', '공지', '수혜자']):\n",
    "            return 1\n",
    "        if any(k in q for k in ['기간', '일정', '날짜', '신청', '수령', '방법']):\n",
    "            return 2\n",
    "        if any(k in q for k in ['대상', '기준', '자격', '조건']):\n",
    "            return 0\n",
    "\n",
    "    # 2. 강의평 관련\n",
    "    if '강의평' in q or '강의 평가' in q:\n",
    "        if any(k in q for k in ['어디', '사이트', '조회', '확인']):\n",
    "            return 1\n",
    "        return 0\n",
    "\n",
    "    # 3. 상세 절차/방법 안내\n",
    "    if any(k in q for k in ['방법', '절차', '이용법', '이용 방법', '안내해', '알려주']):\n",
    "        if '도서관' in q or '시설' in q or '예약' in q or '복사기' in q:\n",
    "            return 1\n",
    "        if '셔틀' in q or '버스' in q:\n",
    "            return 4\n",
    "        if '졸업' in q or '전공' in q or '학점' in q:\n",
    "            return 0\n",
    "        if '신청' in q or '수강' in q:\n",
    "            return 2\n",
    "\n",
    "    # 4. 수강신청 관련\n",
    "    if '수강신청' in q:\n",
    "        if any(k in q for k in ['기간', '일정', '정정', '대기', '팁', '사이트', '오류']):\n",
    "            return 2\n",
    "\n",
    "    # 5. 공지/알림/공지사항\n",
    "    if any(k in q for k in ['공지', '알림', '안내', '공지사항', '공고']):\n",
    "        return 1\n",
    "\n",
    "    # 6. 학식/식단\n",
    "    if any(k in q for k in ['학식', '식단', '메뉴', '밥', '중식', '석식', '아침', '점심', '석식']):\n",
    "        return 3\n",
    "\n",
    "    # 7. 셔틀/교통\n",
    "    if any(k in q for k in ['셔틀', '버스', '정류장', '교통', '노선', '막차', '위치']):\n",
    "        return 4\n",
    "\n",
    "    # 8. 일정/기간/날짜/시험/등록금/휴강/복학/방학/출석/중간고사/기말고사\n",
    "    if any(k in q for k in ['일정', '기간', '날짜', '시간', '시험', '등록금', '휴강', '복학', '방학', '출석', '중간', '기말']):\n",
    "        return 2\n",
    "\n",
    "    # 9. 졸업/전공/학점/요건/논문/유예/인증/필수/인턴/교환학생\n",
    "    if any(k in q for k in ['졸업', '전공', '학점', '교양', '요건', '논문', '유예', '인증', '필수', '인턴', '교환학생', '동아리', '멘토링', '실습']):\n",
    "        return 0\n",
    "\n",
    "    # 10. 도서관/예약/자리/좌석/복사기 등\n",
    "    if any(k in q for k in ['도서관', '예약', '자리', '좌석', '복사기']):\n",
    "        return 1\n",
    "\n",
    "    # 11. 와이파이/비번/인터넷/접속\n",
    "    if any(k in q for k in ['와이파이', '비번', '인터넷', '접속']):\n",
    "        return 1\n",
    "\n",
    "    # 12. 캠퍼스 지도, 상벌점, 학생증 등도 안내(1)\n",
    "    if any(k in q for k in ['지도', '상벌점', '학생증']):\n",
    "        return 1\n",
    "\n",
    "    # 나머지는 기존 예측 유지\n",
    "    return predicted_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "effa69b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5n/fm4k5wz95cgg72yh3snfpy8w0000gn/T/ipykernel_48806/2793737635.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4edca58d183841c8aa0ef7f06385f4ea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved predictions to ../outputs/cls_output.json\n"
     ]
    }
   ],
   "source": [
    "# 베스트 모델 로드\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "model.eval()\n",
    "\n",
    "# 기존 코드와 다르게 enumerate(test_loader)로 전체 인덱스 추적\n",
    "results = []\n",
    "cur_idx = 0  # 전체 test_data 인덱스\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader):\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits.cpu().numpy()\n",
    "        preds = np.argmax(logits, axis=1)\n",
    "        batch_size = len(preds)\n",
    "        for i in range(batch_size):\n",
    "            question = test_data[cur_idx]['question']\n",
    "            pred = int(preds[i])\n",
    "            #refined_pred = refine_label(question, pred)  # <- 여기!\n",
    "            results.append({\n",
    "                \"question\": question,\n",
    "                \"label\": pred # refined_pred\n",
    "            })\n",
    "            cur_idx += 1  # 전체 test 인덱스만 누적!\n",
    "\n",
    "\n",
    "# json 저장\n",
    "with open(OUTPUT_PATH, 'w', encoding='utf-8') as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Saved predictions to {OUTPUT_PATH}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46a4fe3",
   "metadata": {},
   "source": [
    "검증 데이터 추가 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4882e457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Accuracy: 0.9375\n",
      "Valid Macro F1: 0.9358911968896706\n"
     ]
    }
   ],
   "source": [
    "# valid set 성능 재확인\n",
    "trues, preds = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for batch in valid_loader:\n",
    "        input_ids = batch['input_ids'].to(DEVICE)\n",
    "        attention_mask = batch['attention_mask'].to(DEVICE)\n",
    "        labels = batch['labels'].to(DEVICE)\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        batch_preds = np.argmax(outputs.logits.cpu().numpy(), axis=1)\n",
    "        preds.extend(batch_preds)\n",
    "        trues.extend(labels.cpu().numpy())\n",
    "\n",
    "print(\"Valid Accuracy:\", accuracy_score(trues, preds))\n",
    "print(\"Valid Macro F1:\", f1_score(trues, preds, average='macro'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76792bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
